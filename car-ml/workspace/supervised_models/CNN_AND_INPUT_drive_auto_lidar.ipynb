{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model to drive and takeover obstacles thanks to images and lidar informations\n",
    "\n",
    "Author : Johan Jublanc\n",
    "    \n",
    "Date : 14/11/2019\n",
    "\n",
    "Description : \n",
    "\n",
    "Load the images, lidar information and action to train a model to drive and avoid obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.183798Z",
     "start_time": "2019-06-03T14:37:35.574034Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import pathlib\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import IPython.display as display\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.losses import MSE, MSLE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "from xebikart.images import transformer as T\n",
    "import xebikart.dataset as dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.189742Z",
     "start_time": "2019-06-03T14:37:37.185665Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager Execution allows to evaluate operations immediately without building graphs\n",
    "note : Only needed when not using TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "# dataset parameters\n",
    "tubes_root_folder = \"file:/workspace/xebikart-ml-tubes\"\n",
    "tubes_folders = [\"tub_42_19-11-19\"]\n",
    "\n",
    "test_size=0.2\n",
    "\n",
    "# training parameters\n",
    "batch_size = 16\n",
    "shuffle_size = 200\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:53:28.539899Z",
     "start_time": "2019-05-30T15:53:28.537757Z"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tubes from : https://github.com/xebia-france/xebikart-ml-tubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders, tubes_extension=\".tar.gz\")\n",
    "tubes_df = raw_tubes_df.rename(columns={\"cam/image_array\": \"images_path\", \n",
    "                                        \"user/angle\": \"angles\",\n",
    "                                        \"user/throttle\": \"throttles\",\n",
    "                                        \"lidar/distances\":\"lidar/output\"}).reset_index(drop=True)\n",
    "tubes_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:53:28.539899Z",
     "start_time": "2019-05-30T15:53:28.537757Z"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Custom lidar data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_df[\"lidar/clipped_distances\"] = tubes_df[\"lidar/output\"].apply(lambda distances: np.clip(distances, 0, 600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:13.603660Z",
     "start_time": "2019-05-30T15:54:13.601387Z"
    }
   },
   "source": [
    "#### **- Display some examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_values = tubes_df.sample(3).reset_index().iterrows()\n",
    "\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "\n",
    "for n, sample in random_values:\n",
    "    \n",
    "    lidar_360 = sample['clipped_distances']\n",
    "    random_image_path = sample[\"images_path\"]\n",
    "    angle = sample[\"angles\"]\n",
    "    throttle = sample[\"throttles\"]\n",
    "    image = mpimg.imread(random_image_path)\n",
    "    \n",
    "    plt.subplot(2, 3, n+1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"ang : {0:.3f}  /  throttle : {0:.3f}\".format(angle, throttle))\n",
    "    \n",
    "    plt.subplot(2, 3, n+4, projection='polar')\n",
    "    plt.plot(np.deg2rad(range(360)), lidar_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Display some sample distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
    "axs[0].hist(tubes_df.angles)\n",
    "axs[0].set_title('distribution angles')\n",
    "axs[1].hist(tubes_df.throttles)\n",
    "axs[1].set_title('distribution throttles')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:13.603660Z",
     "start_time": "2019-05-30T15:54:13.601387Z"
    }
   },
   "source": [
    "#### **- Display some gif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tubes = 300\n",
    "offset_tubes = 250\n",
    "\n",
    "rows = tubes_df[offset_tubes:(offset_tubes+num_tubes)].iterrows()\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(17,10))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "# Axes (img, lidar)\n",
    "ax_im = fig.add_subplot(1, 2, 1)\n",
    "ax_lid = fig.add_subplot(1, 2, 2, projection='polar')\n",
    "\n",
    "def update(df_row):\n",
    "    index, row = df_row\n",
    "    \n",
    "    # Plot\n",
    "    ax_im.imshow(mpimg.imread(row[\"images_path\"]))\n",
    "    ax_im.set_xlabel(\"ang : {0:.3f}  /  throttle : {0:.3f}\".format(row[\"angles\"], row[\"throttles\"]))\n",
    "    ax_lid.clear()\n",
    "    ax_lid.plot(np.deg2rad(range(360)), row['lidar/clipped_distances'])\n",
    "    return ax_im, ax_lid\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=rows, interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anim.save('lidar.gif', dpi=80, writer='imagemagick')\n",
    "display(HTML(anim.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:48.159163Z",
     "start_time": "2019-05-30T15:54:48.156791Z"
    }
   },
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Images will be :**\n",
    "- Loaded\n",
    "    - Read images\n",
    "    - Decode jpeg images into uint8 tensor\n",
    "- Cropped\n",
    "    - Crop images on the lower part\n",
    "- Augmented\n",
    "    - Brightness : Adjust the brightness of images by a random factor.\n",
    "    - Saturation : Adjust the saturation of images by a random factor (must be RGB images)\n",
    "    - Contrast : Adjust the contrast of images by a random factor.\n",
    "    - Jpeg quality : Randomly changes jpeg encoding quality for inducing jpeg noise\n",
    "- Normalized\n",
    "    - Image are converted into Float32 between 0 and 1\n",
    "- Edged\n",
    "    - Convert tensor uint8 type into float32 type\n",
    "    - Convert rgb images to grayscale\n",
    "    - Reshape into [1, 80, 160, 1] tensor\n",
    "    - Apply sobel filter (see https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "    - Reshape into [80, 160, 2] tensor\n",
    "    - Select image gradient up to 0.3\n",
    "    - Binarize images by setting elements to 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **- Display some examples before and after preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_fn = T.generate_crop_fn(left_margin=0, width=160, height_margin=40, height=80)\n",
    "clip_max = 600\n",
    "\n",
    "def lidar_preprocess(lidar):\n",
    "    lidar = tf.clip_by_value(lidar, clip_value_min = 0, clip_value_max=clip_max)\n",
    "    lidar = 1 - lidar/clip_max\n",
    "    return lidar\n",
    "\n",
    "def load_augmentation_preprocess(image_path):\n",
    "    tf_image = T.read_image(image_path)\n",
    "    tf_image = T.normalize(tf_image)\n",
    "    tf_image = crop_fn(tf_image)\n",
    "    tf_image = T.data_augmentation(tf_image)\n",
    "    tf_image = T.edges(tf_image)\n",
    "    return tf_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path_lidar_output = tubes_df.sample()[[\"images_path\",\"lidar/output\"]].values[0]\n",
    "random_image_path = random_image_path_lidar_output[0]\n",
    "\n",
    "tf_image_original   = T.read_image(random_image_path)\n",
    "tf_image_cropped    = crop_fn(tf_image_original)\n",
    "tf_image_augmented  = T.data_augmentation(tf_image_cropped)\n",
    "tf_image_normalized = T.normalize(tf_image_augmented)\n",
    "tf_image_edged      = T.edges(tf_image_normalized)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15,15), constrained_layout=True)\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].imshow(tf_image_original)\n",
    "axs[1].set_title(\"Cropping\")\n",
    "axs[1].imshow(tf_image_cropped)\n",
    "axs[2].set_title(\"Augmented\")\n",
    "axs[2].imshow(tf_image_augmented)\n",
    "axs[3].set_title(\"Preprocessed channel 1\")\n",
    "axs[3].imshow(tf_image_edged[:,:,0],cmap='gray')\n",
    "axs[4].set_title(\"Preprocessed channel 2\")\n",
    "axs[4].imshow(tf_image_edged[:,:,1],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a dataset of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Split data into test/train datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : We only use angle as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_and_lidar_outputs = [x for x in zip(tubes_df[\"images_path\"].tolist(), tubes_df[\"lidar/output\"].tolist())]\n",
    "metas_angle = tubes_df[\"angles\"].tolist()\n",
    "metas_throttle = tubes_df[\"throttles\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.201319Z",
     "start_time": "2019-06-03T14:37:37.196764Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images_path_lidar_outputs, test_images_path_lidar_outputs, train_metas, test_metas = train_test_split(images_path_and_lidar_outputs, metas_angle, test_size=test_size)\n",
    "print('Train set :', len(train_images_path_lidar_outputs), 'images')\n",
    "print('Test set :', len(test_images_path_lidar_outputs), 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Create tensor for train and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(filepath, lidar, label, BATCH_SIZE = 32, SHUFFLE_SIZE = 200, NUM_EPOCHS = 50, NUM_REPEAT=200):\n",
    "    ds_x = tf.data.Dataset.from_tensor_slices(filepath)\n",
    "    ds_x = ds_x.map(load_augmentation_preprocess)\n",
    "    ds_l = tf.data.Dataset.from_tensor_slices(lidar)\n",
    "    ds_l = ds_l.map(lidar_preprocess)\n",
    "    ds_y = tf.data.Dataset.from_tensor_slices(label)\n",
    "    ds_xl_y = tf.data.Dataset.zip(((ds_x, ds_l), ds_y)).shuffle(SHUFFLE_SIZE).repeat(NUM_REPEAT).batch(BATCH_SIZE).prefetch(1)\n",
    "    \n",
    "    return ds_xl_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = [x[0] for x in train_images_path_lidar_outputs]\n",
    "train_lidar_outputs = [x[1] for x in train_images_path_lidar_outputs]\n",
    "test_images_path = [x[0] for x in test_images_path_lidar_outputs]\n",
    "test_lidar_outputs = [x[1] for x in test_images_path_lidar_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_lidar_outputs)==len(train_images_path))\n",
    "print(len(test_lidar_outputs)==len(test_images_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = input_fn(train_images_path, train_lidar_outputs, train_metas)\n",
    "ds_test = input_fn(test_images_path, train_lidar_outputs, test_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.output_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape = ds_train.output_shapes[0][0][1:4], name='main_input')\n",
    "lidar_input = Input(shape = (ds_train.output_shapes[0][1][1],), name='lidar_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "## convolutional layers ##\n",
    "##########################\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 16,\n",
    "                           kernel_size = (5,5), \n",
    "                           activation='relu', \n",
    "                           kernel_regularizer=l1_l2(l1=0.1, l2=0.01))(main_input)\n",
    "x = tf.keras.layers.MaxPooling2D((3,3))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 32,\n",
    "                           kernel_size = (3,3), \n",
    "                           activation='relu', \n",
    "                           kernel_regularizer=l1_l2(l1=0.1, l2=0.01))(x)\n",
    "x = tf.keras.layers.MaxPooling2D((3,3))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 64,\n",
    "                           kernel_size = (3,3), \n",
    "                           activation='relu', \n",
    "                           kernel_regularizer=l1_l2(l1=0.1, l2=0.01))(x)\n",
    "# flatten\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "# add lidar inputs\n",
    "\n",
    "\n",
    "y = tf.keras.layers.Dense(360, activation ='relu')(lidar_input)\n",
    "y = tf.keras.layers.Dropout(0.6)(y)\n",
    "y = tf.keras.layers.Dense(180, activation ='relu')(y)\n",
    "y = tf.keras.layers.Dropout(0.4)(y)\n",
    "y = tf.keras.layers.Dense(36, activation ='sigmoid')(y)\n",
    "y = tf.keras.layers.Dropout(0.4)(y)\n",
    "x = tf.keras.layers.concatenate([x, y])\n",
    "\n",
    "##################\n",
    "## dense layers ##\n",
    "##################\n",
    "\n",
    "# x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.6)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "output = tf.keras.layers.Dense(1, activation='linear')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, lidar_input], outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:38.649197Z",
     "start_time": "2019-06-03T14:37:38.436830Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate, decay=1e-6), loss=\"mae\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- How to choose and interpret loss :**\n",
    "\n",
    "Mean Absolute Error (MAE) is the absolute value of the substraction of predicted from actual value\n",
    "Let's see an example : \n",
    "Actual angle = 0.21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:45:56.323265Z",
     "start_time": "2019-06-03T14:37:38.658530Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"drive_auto_image_and_lidar\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"images\": str(tubes_folders),\n",
    "        \"nb_images\": len(train_images_path),\n",
    "        \"epochs\": n_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate\n",
    "    })\n",
    "    mlflow.tensorflow.autolog()\n",
    "    history = model.fit(x=ds_train,\n",
    "                    steps_per_epoch=len(train_metas)//batch_size,\n",
    "                    epochs=n_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=ds_test,\n",
    "                    validation_steps=len(test_metas)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.columns=['loss','val_loss']\n",
    "    hist_df.index = np.arange(1, len(hist_df)+1)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(hist_df.val_loss, lw=3, label='Validation Loss')\n",
    "    plt.plot(hist_df.loss, lw=3, label='Training Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.legend(loc=0)\n",
    "    plt.ylim(0,20)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- steps:** Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of None. If x is a tf.data dataset or a dataset iterator, and steps is None, predict will run until the input dataset is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:46:04.003630Z",
     "start_time": "2019-06-03T14:45:56.326242Z"
    }
   },
   "outputs": [],
   "source": [
    "train_angles = model.predict(ds_test, steps=len(test_metas)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:58:55.346167Z",
     "start_time": "2019-06-03T14:58:55.173698Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_angles, columns = ['angles'])\n",
    "df.angles.hist(bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:56:58.668531Z",
     "start_time": "2019-06-03T14:56:58.374150Z"
    }
   },
   "outputs": [],
   "source": [
    "df.angles.plot.kde()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
