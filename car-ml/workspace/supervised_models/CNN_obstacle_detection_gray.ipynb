{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model to detect images with an obstacle on track and make a lite version of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author : RaphaÃ«l Matusiak / Johan Jublanc\n",
    "    \n",
    "Date : 02/10/2019\n",
    "\n",
    "Description : \n",
    "\n",
    "Train a model to detect obstacles and use the Python interpreter to load a .tflite file and run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO :_\n",
    "* Generalize this procedure to each model in the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.183798Z",
     "start_time": "2019-06-03T14:37:35.574034Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0d3b75645a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import pathlib\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import IPython.display as display\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import MSLE, MAE, MSE\n",
    "from tensorflow.keras.losses import MSE, MSLE\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from xebikart.images import transformer as T\n",
    "import xebikart.dataset as dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.compat.v1 import lite\n",
    "from xebikart.lite_functions import predictor_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.189742Z",
     "start_time": "2019-06-03T14:37:37.185665Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager Execution allows to evaluate operations immediately without building graphs\n",
    "note : Only needed when not using TF 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset parameters\n",
    "tubes_root_folder = 'file:/workspace/xebikart-ml-tubes'\n",
    "tubes_folders_obstacle = [\"tub.v8.02\"]\n",
    "tubes_folders_road = [\"tub.v5.01\", \"tub.v5.02\", \"tub.v4.02\"]#, \"tub.v5.03\", \"tub.v5.04\"]\n",
    "\n",
    "test_size=0.2\n",
    "\n",
    "# training parameters\n",
    "batch_size = 16\n",
    "shuffle_size = 200\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# model name\n",
    "model_name = \"obstacle_detection_gray\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:53:28.539899Z",
     "start_time": "2019-05-30T15:53:28.537757Z"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tubes from : https://github.com/xebia-france/xebikart-ml-tubes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the tubes from tar.gz files into pd data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders_road, tubes_extension=\".tar.gz\")\n",
    "road_tubes_df['label'] = 0\n",
    "\n",
    "obstacle_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders_obstacle, tubes_extension=\".tar.gz\")\n",
    "obstacle_tubes_df['label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "tubes_df = pd.concat([road_tubes_df, obstacle_tubes_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_df = tubes_df.rename(columns={\"cam/image_array\": \"images_path\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:13.603660Z",
     "start_time": "2019-05-30T15:54:13.601387Z"
    }
   },
   "source": [
    "#### **- Display some examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.474183Z",
     "start_time": "2019-06-03T14:37:37.466159Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15,5), constrained_layout=True)\n",
    "fig.suptitle(\"label\", fontsize=20)\n",
    "\n",
    "for n, sample in tubes_df.sample(3).reset_index().iterrows():\n",
    "    random_image_path = sample[\"images_path\"]\n",
    "    label = sample[\"label\"]\n",
    "    image = mpimg.imread(random_image_path) \n",
    "    axs[n].set_title(label)\n",
    "    axs[n].imshow(image)\n",
    "    axs[n].get_xaxis().set_visible(False)\n",
    "    axs[n].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Display some sample distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'no obstacles', 'obstacles'\n",
    "sizes = [len(tubes_df[tubes_df.label == 0]), len(tubes_df[tubes_df.label == 1])]\n",
    "explode = (0, 0.1)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:48.159163Z",
     "start_time": "2019-05-30T15:54:48.156791Z"
    }
   },
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_process_from_path(process):\n",
    "    \n",
    "    def process_from_path(path):\n",
    "        tf_image = T.read_image(path)\n",
    "        return process(tf_image)\n",
    "    \n",
    "    return process_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = T.normalize_gray_scale\n",
    "preprocess_from_path = get_process_from_path(T.normalize_gray_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = tubes_df.sample()[\"images_path\"].values[0]\n",
    "\n",
    "tf_image_original = T.read_image(random_image_path)\n",
    "tf_processed_image = preprocess_from_path(random_image_path)\n",
    "\n",
    "# go back to 3 channels\n",
    "tf_processed_image = tf.image.grayscale_to_rgb(tf_processed_image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15,15), constrained_layout=True)\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].imshow(tf_image_original)\n",
    "axs[1].set_title(\"processed\")\n",
    "axs[1].imshow(tf_processed_image,cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a dataset of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Split data into test/train datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : We only use angle as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = tubes_df[\"images_path\"].tolist()\n",
    "label = tubes_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.201319Z",
     "start_time": "2019-06-03T14:37:37.196764Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images_path, test_images_path, train_metas, test_metas = train_test_split(images_path, label, test_size=test_size)\n",
    "print('Train set :', len(train_images_path), 'images')\n",
    "print('Test set :', len(test_images_path), 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Create tensor for train and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(filepath, label, BATCH_SIZE = batch_size, SHUFFLE_SIZE = 400, NUM_EPOCHS = n_epochs):\n",
    "    ds_x = tf.data.Dataset.from_tensor_slices(filepath)\n",
    "    ds_x = ds_x.map(preprocess_from_path)\n",
    "    ds_y = tf.data.Dataset.from_tensor_slices(label)\n",
    "    ds_x_y = tf.data.Dataset.zip((ds_x, ds_y)).shuffle(SHUFFLE_SIZE).repeat(NUM_EPOCHS).batch(BATCH_SIZE).prefetch(1)\n",
    "    \n",
    "    return ds_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = input_fn(train_images_path, train_metas)\n",
    "ds_test = input_fn(test_images_path, test_metas, NUM_EPOCHS=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(120, 160,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:38.649197Z",
     "start_time": "2019-06-03T14:37:38.436830Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate, decay=learning_rate/n_epochs), loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:45:56.323265Z",
     "start_time": "2019-06-03T14:37:38.658530Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"detect_obstacle\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"images_exit\": str(tubes_folders_obstacle),\n",
    "        \"images_road\": str(tubes_folders_road),\n",
    "        \"nb_images\": len(train_images_path),\n",
    "        \"epochs\": n_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate\n",
    "    })\n",
    "    mlflow.tensorflow.autolog()\n",
    "    history = model.fit(x=ds_train,\n",
    "                    steps_per_epoch=len(train_metas)//batch_size,\n",
    "                    epochs=n_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=ds_test,\n",
    "                    validation_steps=len(test_metas)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.columns=['loss','val_loss']\n",
    "    hist_df.index = np.arange(1, len(hist_df)+1)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(hist_df.val_loss, lw=3, label='Validation Loss')\n",
    "    plt.plot(hist_df.loss, lw=3, label='Training Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.legend(loc=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation & Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model from mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_runid = \"93c5025795394f50adfa5d6db4319c1b\"\n",
    "#model = mlflow.keras.load_model(f\"runs:/{model_runid}/model\", compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:46:04.003630Z",
     "start_time": "2019-06-03T14:45:56.326242Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(ds_test, use_multiprocessing=True, workers=12, steps = None)#len(test_metas)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:58:55.346167Z",
     "start_time": "2019-06-03T14:58:55.173698Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_pred, columns = ['label'])\n",
    "df.label.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Visualisation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_random = np.random.randint(len(test_metas))\n",
    "\n",
    "random_image_path_0 = [(test_images_path[nb_random])]\n",
    "random_image_label_0 = [test_metas[nb_random]]\n",
    "\n",
    "ds_visu_test_0 = input_fn(random_image_path_0, random_image_label_0)\n",
    "\n",
    "nb_random = np.random.randint(len(test_metas))\n",
    "\n",
    "random_image_path_1 = [(test_images_path[nb_random])]\n",
    "random_image_label_1 = [test_metas[nb_random]]\n",
    "\n",
    "ds_visu_test_1 = input_fn(random_image_path_1, random_image_label_1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15,5), constrained_layout=True)\n",
    "axs[0].set_title(\"Value ({}) : Predict ({})\".format(random_image_label_0, model.predict(ds_visu_test_0)[0]))\n",
    "axs[0].imshow(T.read_image(random_image_path_0[0]))\n",
    "axs[1].set_title(\"Value ({}) : Predict ({})\".format(random_image_label_1, model.predict(ds_visu_test_1)[0]))\n",
    "axs[1].imshow(T.read_image(random_image_path_1[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Interpretation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true=test_metas, probas_pred=test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, precision[:-1], '--', label='precision')\n",
    "plt.plot(thresholds, recall[:-1], '--', label='recall')\n",
    "plt.xlabel('threshold')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model in .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/{}.h5\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model into a lite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = lite.TFLiteConverter.from_keras_model_file(\"models/{}.h5\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"{}.tflite\".format(model_name), \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the predictor and test it on random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = predictor_builder(model_name + '.tflite', preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = []\n",
    "for i in range(12):\n",
    "    random_image_path.append(tubes_df.sample()[\"images_path\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4,figsize=(20,15), constrained_layout=True)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        # function pre-defined are used to compute the prediction\n",
    "        tf_image = T.read_image(random_image_path[4*i +j])\n",
    "        prediction = predictor(tf_image)[0]\n",
    "\n",
    "        # eaxh image in shown with the prediction\n",
    "        axs[i][j].set_title(\"Prediction = {}\".format(prediction))\n",
    "        axs[i][j].imshow(tf.reshape(tf_image,(tf_image.shape[0],tf_image.shape[1],3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
