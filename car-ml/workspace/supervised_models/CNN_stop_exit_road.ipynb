{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<center>Using CNN to stopping the car when it comes off the road<center>**\n",
    "    \n",
    "In this notebook, you can download images obtained with the donkey car. You can use them to launch a training in order to get a model for the donkey car.\n",
    "Several options are available :\n",
    "\n",
    "- The number of image to learn from\n",
    "- The possibility to invert them to also learn turning right\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.183798Z",
     "start_time": "2019-06-03T14:37:35.574034Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import pathlib\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import IPython.display as display\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import MSLE, MAE, MSE\n",
    "from tensorflow.keras.losses import MSE, MSLE\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from xebikart.images import transformer as T\n",
    "import xebikart.dataset as dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.189742Z",
     "start_time": "2019-06-03T14:37:37.185665Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager Execution allows to evaluate operations immediately without building graphs\n",
    "note : Only needed when not using TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "# dataset parameters\n",
    "tubes_root_folder = 'file:/workspace/xebikart-ml-tubes'\n",
    "tubes_folders_exit = [\"tub.v7.01\", \"tub.v7.02\"]\n",
    "tubes_folders_road = [\"tub.v5.01\", \"tub.v5.02\"]#, \"tub.v5.03\", \"tub.v5.04\"]\n",
    "\n",
    "test_size=0.2\n",
    "\n",
    "# training parameters\n",
    "batch_size = 32\n",
    "shuffle_size = 200\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:53:28.539899Z",
     "start_time": "2019-05-30T15:53:28.537757Z"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tubes from : https://github.com/xebia-france/xebikart-ml-tubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "road_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders_road, tubes_extension=\".tar.gz\")\n",
    "road_tubes_df['label'] = 0\n",
    "exit_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders_exit, tubes_extension=\".tar.gz\")\n",
    "exit_tubes_df['label'] = 1\n",
    "road_tubes_df = road_tubes_df.rename(columns={\"cam/image_array\": \"images_path\"})\n",
    "exit_tubes_df = exit_tubes_df.rename(columns={\"cam/image_array\": \"images_path\"})\n",
    "tubes_df = pd.concat([road_tubes_df, exit_tubes_df]).reset_index(drop=True)\n",
    "tubes_df = tubes_df.drop([\"user/angle\", \"user/throttle\", \"user/mode\", \"timestamp\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:13.603660Z",
     "start_time": "2019-05-30T15:54:13.601387Z"
    }
   },
   "source": [
    "#### **- Display some examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.474183Z",
     "start_time": "2019-06-03T14:37:37.466159Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15,5), constrained_layout=True)\n",
    "fig.suptitle(\"label\", fontsize=20)\n",
    "\n",
    "for n, sample in tubes_df.sample(3).reset_index().iterrows():\n",
    "    random_image_path = sample[\"images_path\"]\n",
    "    label = sample[\"label\"]\n",
    "    image = mpimg.imread(random_image_path) \n",
    "    axs[n].set_title(label)\n",
    "    axs[n].imshow(image)\n",
    "    axs[n].get_xaxis().set_visible(False)\n",
    "    axs[n].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Display some sample distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'on the road', 'Out of the road'\n",
    "sizes = [len(tubes_df[tubes_df.label == 0]), len(tubes_df[tubes_df.label == 1])]\n",
    "explode = (0, 0.1)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:48.159163Z",
     "start_time": "2019-05-30T15:54:48.156791Z"
    }
   },
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_fn = T.generate_crop_fn(left_margin=0, width=160, height_margin=80, height=40)\n",
    "\n",
    "def load_augmentation_preprocess(image_path):\n",
    "    tf_image = T.read_image(image_path)\n",
    "    tf_image = T.normalize(tf_image)\n",
    "    tf_image = tf.image.rgb_to_grayscale(tf_image)\n",
    "    tf_image = crop_fn(tf_image)\n",
    "    return tf_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = tubes_df.sample()[\"images_path\"].values[0]\n",
    "\n",
    "tf_image_original   = T.read_image(random_image_path)\n",
    "tf_image_normalized = T.normalize(tf_image_original)/255.0\n",
    "tf_image_cropped    = crop_fn(tf_image_normalized)\n",
    "tf_image_grayscaled = tf.image.rgb_to_grayscale(tf_image_cropped)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,15), constrained_layout=True)\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].imshow(tf_image_original)\n",
    "axs[1].set_title(\"Cropping & normalized\")\n",
    "axs[1].imshow(tf_image_cropped)\n",
    "axs[2].set_title(\"Preprocessed\")\n",
    "axs[2].imshow(tf_image_grayscaled[:,:,0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a dataset of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Split data into test/train datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : We only use angle as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = tubes_df[\"images_path\"].tolist()\n",
    "label = tubes_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.201319Z",
     "start_time": "2019-06-03T14:37:37.196764Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images_path, test_images_path, train_metas, test_metas = train_test_split(images_path, label, test_size=test_size)\n",
    "print('Train set :', len(train_images_path), 'images')\n",
    "print('Test set :', len(test_images_path), 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Create tensor for train and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(filepath, label, BATCH_SIZE = 32, SHUFFLE_SIZE = 200, NUM_EPOCHS = 50):\n",
    "    ds_x = tf.data.Dataset.from_tensor_slices(filepath)\n",
    "    ds_x = ds_x.map(load_augmentation_preprocess)\n",
    "    ds_y = tf.data.Dataset.from_tensor_slices(label)\n",
    "    ds_x_y = tf.data.Dataset.zip((ds_x, ds_y)).shuffle(SHUFFLE_SIZE).repeat(NUM_EPOCHS).batch(BATCH_SIZE).prefetch(1)\n",
    "    \n",
    "    return ds_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = input_fn(train_images_path, train_metas)\n",
    "ds_test = input_fn(test_images_path, test_metas, NUM_EPOCHS=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(40, 160,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:38.649197Z",
     "start_time": "2019-06-03T14:37:38.436830Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate, decay=learning_rate/n_epochs), loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:45:56.323265Z",
     "start_time": "2019-06-03T14:37:38.658530Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"detect_road_exit\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"images_exit\": str(tubes_folders_exit),\n",
    "        \"images_road\": str(tubes_folders_road),\n",
    "        \"nb_images\": len(train_images_path),\n",
    "        \"epochs\": n_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate\n",
    "    })\n",
    "    mlflow.tensorflow.autolog()\n",
    "    history = model.fit(x=ds_train,\n",
    "                    steps_per_epoch=len(train_metas)//batch_size,\n",
    "                    epochs=n_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=ds_test,\n",
    "                    validation_steps=len(test_metas)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.columns=['loss','val_loss']\n",
    "    hist_df.index = np.arange(1, len(hist_df)+1)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(hist_df.val_loss, lw=3, label='Validation Loss')\n",
    "    plt.plot(hist_df.loss, lw=3, label='Training Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.legend(loc=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation & Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:46:04.003630Z",
     "start_time": "2019-06-03T14:45:56.326242Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(ds_test, use_multiprocessing=True, workers=12, steps = None)#len(test_metas)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:58:55.346167Z",
     "start_time": "2019-06-03T14:58:55.173698Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_pred, columns = ['label'])\n",
    "df.label.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Visualisation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_random = np.random.randint(len(test_metas))\n",
    "\n",
    "random_image_path_0 = [(test_images_path[nb_random])]\n",
    "random_image_label_0 = [test_metas[nb_random]]\n",
    "\n",
    "ds_visu_test_0 = input_fn(random_image_path_0, random_image_label_0)\n",
    "\n",
    "nb_random = np.random.randint(len(test_metas))\n",
    "\n",
    "random_image_path_1 = [(test_images_path[nb_random])]\n",
    "random_image_label_1 = [test_metas[nb_random]]\n",
    "\n",
    "ds_visu_test_1 = input_fn(random_image_path_1, random_image_label_1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15,5), constrained_layout=True)\n",
    "axs[0].set_title(\"Value ({}) : Predict ({})\".format(random_image_label_0, model.predict(ds_visu_test_0)[0]))\n",
    "axs[0].imshow(T.read_image(random_image_path_0[0]))\n",
    "axs[1].set_title(\"Value ({}) : Predict ({})\".format(random_image_label_1, model.predict(ds_visu_test_1)[0]))\n",
    "axs[1].imshow(T.read_image(random_image_path_1[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Interpretation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_true=test_metas, probas_pred=test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thresholds, precision[:-1], '--', label='precision')\n",
    "plt.plot(thresholds, recall[:-1], '--', label='recall')\n",
    "plt.xlabel('threshold')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
