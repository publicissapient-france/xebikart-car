{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.183798Z",
     "start_time": "2019-06-03T14:37:35.574034Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import pathlib\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import IPython.display as display\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.losses import MSE, MSLE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "from xebikart.images import transformer as T\n",
    "import xebikart.dataset as dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.189742Z",
     "start_time": "2019-06-03T14:37:37.185665Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager Execution allows to evaluate operations immediately without building graphs\n",
    "note : Only needed when not using TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "# dataset parameters\n",
    "tubes_root_folder = \"file:/workspace/xebikart-ml-tubes\"\n",
    "tubes_folders = [\n",
    "    \"tub.v5.01\"\n",
    "]\n",
    "test_size=0.2\n",
    "\n",
    "# training parameters\n",
    "batch_size = 32\n",
    "shuffle_size = 200\n",
    "n_epochs = 200\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:53:28.539899Z",
     "start_time": "2019-05-30T15:53:28.537757Z"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tubes from : https://github.com/xebia-france/xebikart-ml-tubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders, tubes_extension=\".tar.gz\")\n",
    "tubes_df = raw_tubes_df.rename(columns={\"cam/image_array\": \"images_path\", \"user/angle\": \"angles\", \"user/throttle\": \"throttles\"})\n",
    "tubes_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:53:28.539899Z",
     "start_time": "2019-05-30T15:53:28.537757Z"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:13.603660Z",
     "start_time": "2019-05-30T15:54:13.601387Z"
    }
   },
   "source": [
    "#### **- Display some examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.474183Z",
     "start_time": "2019-06-03T14:37:37.466159Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15,5), constrained_layout=True)\n",
    "fig.suptitle(\"Angle / Throttle\", fontsize=20)\n",
    "\n",
    "for n, sample in tubes_df.sample(3).reset_index().iterrows():\n",
    "    random_image_path = sample[\"images_path\"]\n",
    "    angle = sample[\"angles\"]\n",
    "    throttle = sample[\"throttles\"]\n",
    "    image = mpimg.imread(random_image_path) \n",
    "    axs[n].set_title(f\"{angle} / {throttle}\")\n",
    "    axs[n].imshow(image)\n",
    "    axs[n].get_xaxis().set_visible(False)\n",
    "    axs[n].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Display some sample distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
    "axs[0].hist(tubes_df.angles)\n",
    "axs[0].set_title('distribution angles')\n",
    "axs[1].hist(tubes_df.throttles)\n",
    "axs[1].set_title('distribution throttles')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:48.159163Z",
     "start_time": "2019-05-30T15:54:48.156791Z"
    }
   },
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Images will be :**\n",
    "- Loaded\n",
    "    - Read images\n",
    "    - Decode jpeg images into uint8 tensor\n",
    "- Cropped\n",
    "    - Crop images on the lower part\n",
    "- Augmented\n",
    "    - Brightness : Adjust the brightness of images by a random factor.\n",
    "    - Saturation : Adjust the saturation of images by a random factor (must be RGB images)\n",
    "    - Contrast : Adjust the contrast of images by a random factor.\n",
    "    - Jpeg quality : Randomly changes jpeg encoding quality for inducing jpeg noise\n",
    "- Normalized\n",
    "    - Image are converted into Float32 between 0 and 1\n",
    "- Edged\n",
    "    - Convert tensor uint8 type into float32 type\n",
    "    - Convert rgb images to grayscale\n",
    "    - Reshape into [1, 80, 160, 1] tensor\n",
    "    - Apply sobel filter (see https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "    - Reshape into [80, 160, 2] tensor\n",
    "    - Select image gradient up to 0.3\n",
    "    - Binarize images by setting elements to 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **- Display some examples before and after preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_fn = T.generate_crop_fn(left_margin=0, width=160, height_margin=40, height=80)\n",
    "\n",
    "def load_augmentation_preprocess(image_path):\n",
    "    tf_image = T.read_image(image_path)\n",
    "    tf_image = T.normalize(tf_image)\n",
    "    tf_image = crop_fn(tf_image)\n",
    "    tf_image = T.data_augmentation(tf_image)\n",
    "    tf_image = T.edges(tf_image)\n",
    "    return tf_image\n",
    "\n",
    "def load_preprocess(image_path):\n",
    "    tf_image = T.read_image(image_path)\n",
    "    tf_image = T.normalize(tf_image)\n",
    "    tf_image = crop_fn(tf_image)\n",
    "    tf_image = T.edges(tf_image)\n",
    "    return tf_image\n",
    "\n",
    "def flip_load_function(load_function):\n",
    "    def load_function_flipped(image_path):\n",
    "        tf_image = load_function(image_path)\n",
    "        tf_image = tf.image.flip_left_right(tf_image)\n",
    "        return tf_image\n",
    "    return load_function_flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = tubes_df.sample()[\"images_path\"].values[0]\n",
    "\n",
    "tf_image_original   = T.read_image(random_image_path)\n",
    "tf_image_cropped    = crop_fn(tf_image_original)\n",
    "tf_image_augmented  = T.data_augmentation(tf_image_cropped)\n",
    "tf_image_normalized = T.normalize(tf_image_augmented)\n",
    "tf_image_edged      = T.edges(tf_image_normalized)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15,15), constrained_layout=True)\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].imshow(tf_image_original)\n",
    "axs[1].set_title(\"Cropping\")\n",
    "axs[1].imshow(tf_image_cropped)\n",
    "axs[2].set_title(\"Augmented\")\n",
    "axs[2].imshow(tf_image_augmented)\n",
    "axs[3].set_title(\"Preprocessed channel 1\")\n",
    "axs[3].imshow(tf_image_edged[:,:,0],cmap='gray')\n",
    "axs[4].set_title(\"Preprocessed channel 2\")\n",
    "axs[4].imshow(tf_image_edged[:,:,1],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a dataset of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO : faire le shuffle à la toute fin_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Split data into test/train datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : We only use angle as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = tubes_df[\"images_path\"].tolist()\n",
    "metas_angle = tubes_df[\"angles\"].tolist()\n",
    "metas_throttle = tubes_df[\"throttles\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_num = [x.split('/')[-1].split('_')[0] for x in images_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path[0]\n",
    "folder_path = \"/root/.keras/datasets/tub.v5.01/\"\n",
    "image_generic_path = \"_cam-image_array_.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.DataFrame({\"path\":images_path, \"num\":images_num})\n",
    "images_df[\"num\"] = images_df[\"num\"].astype(\"int\")\n",
    "images_df = images_df.sort_values(\"num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stack the path of the tubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_stack = [[images_path[ii], images_path[ii+1], images_path[ii+2], images_path[ii+3]] \n",
    "                     for ii in range(len(images_path)-3)]\n",
    "metas_angle_stack = metas_angle[3:len(metas_angle)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path, test_images_path, train_metas, test_metas = train_test_split(images_path_stack, \n",
    "                                                                                metas_angle_stack,\n",
    "                                                                                test_size=test_size)\n",
    "print('Train set :', len(train_images_path), 'images')\n",
    "print('Test set :', len(test_images_path), 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(train_images_path,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_number = random.sample(range(len(train_images_path)),1)[0]\n",
    "\n",
    "random_image_path = train_images_path[random_number]\n",
    "\n",
    "tf_image_original_0 = T.read_image(random_image_path[0])\n",
    "tf_image_original_1 = T.read_image(random_image_path[1])\n",
    "tf_image_original_2 = T.read_image(random_image_path[2])\n",
    "tf_image_original_3 = T.read_image(random_image_path[3])\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15,15), constrained_layout=True)\n",
    "axs[0].set_title(\"t-3\")\n",
    "axs[0].imshow(tf_image_original_0)\n",
    "axs[1].set_title(\"t-2\")\n",
    "axs[1].imshow(tf_image_original_1)\n",
    "axs[2].set_title(\"t-1\")\n",
    "axs[2].imshow(tf_image_original_2)\n",
    "axs[3].set_title(\"t\")\n",
    "axs[3].imshow(tf_image_original_3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metas[random_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Create tensor for train and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_stack(filepath_stack, label, load_type = load_augmentation_preprocess):\n",
    "    \n",
    "    # make a lambda that load and stack the tubes\n",
    "    load_type = load_augmentation_preprocess\n",
    "    load_and_stack = lambda x : tf.stack([load_type(x[0]),\n",
    "                                      load_type(x[1]),\n",
    "                                      load_type(x[2]),\n",
    "                                      load_type(x[3])])\n",
    "    \n",
    "    # get the preprocessed and stacked images to a data of tensors\n",
    "    ds_x = tf.data.Dataset.from_tensor_slices(filepath_stack)\n",
    "    ds_x = ds_x.map(load_and_stack)\n",
    "    \n",
    "    # do the same with the labels\n",
    "    ds_y = tf.data.Dataset.from_tensor_slices(label)\n",
    "    \n",
    "    #finnaly zip both dataset\n",
    "    ds_x_y = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "    \n",
    "    return ds_x_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get the images not augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_not_augmented = input_fn_stack(train_images_path, train_metas, \n",
    "                              load_type = load_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_not_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the data flipped (not augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_meta_flipped = [-ii for ii in train_metas]\n",
    "flipped_load_function = flip_load_function(load_preprocess)\n",
    "\n",
    "ds_train_flipped = input_fn_stack(train_images_path, trains_meta_flipped, \n",
    "                              load_type = flipped_load_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_flipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the data augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_augmented = input_fn_stack(train_images_path, train_metas, \n",
    "                              load_type = load_augmentation_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the data augmented and flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_meta_flipped = [-ii for ii in train_metas]\n",
    "flipped_load_function = flip_load_function(load_augmentation_preprocess)\n",
    "\n",
    "ds_train_augmented_flipped = input_fn_stack(train_images_path, trains_meta_flipped, \n",
    "                              load_type = flipped_load_function)\n",
    "\n",
    "# plt.imshow(flip_load_function(load_preprocess)(train_images_path[0])[:,:,0])\n",
    "# plt.imshow(load_preprocess(train_images_path[0])[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_augmented_flipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conactenate, shuffle and batch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train_not_augmented.concatenate(ds_train_flipped)\n",
    "ds_train = ds_train.concatenate(ds_train_augmented)\n",
    "ds_train = ds_train.concatenate(ds_train_augmented_flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE_SIZE = 200\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "ds_train = ds_train.shuffle(SHUFFLE_SIZE).repeat(NUM_EPOCHS).batch(BATCH_SIZE).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = input_fn_stack(test_images_path, test_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(16, (1,5,5), activation='relu', \n",
    "                 kernel_regularizer=l1_l2(l1=0.1, l2=0.01), \n",
    "                 input_shape=(4, 80, 160, 2)))\n",
    "model.add(MaxPooling3D((1,3,3)))\n",
    "model.add(Conv3D(32, (1,3,3), activation='relu', \n",
    "                 kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "model.add(MaxPooling3D((1,3,3)))\n",
    "model.add(Conv3D(64, (1,3,3), activation='relu', \n",
    "                 kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "model.add(MaxPooling3D((1,2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:38.649197Z",
     "start_time": "2019-06-03T14:37:38.436830Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate, decay=1e-6), loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- How to choose and interpret loss :**\n",
    "\n",
    "Mean Absolute Error (MAE) is the absolute value of the substraction of predicted from actual value\n",
    "Let's see an example : \n",
    "Actual angle = 0.21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:45:56.323265Z",
     "start_time": "2019-06-03T14:37:38.658530Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"convolutional_neural_network\")\n",
    "n_epochs=50\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"images\": str(tubes_folders),\n",
    "        \"nb_images\": len(train_images_path),\n",
    "        \"epochs\": n_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate\n",
    "    })\n",
    "    mlflow.tensorflow.autolog()\n",
    "    history = model.fit(x=ds_train,\n",
    "                    steps_per_epoch=len(train_metas)//batch_size,\n",
    "                    epochs=n_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=ds_test,\n",
    "                    validation_steps=len(test_metas)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO : vérifier que l'opération de concatenation a bien fonctionnée_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO : mettre en cohérence le nombre d'epoch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# cnn_model = mlflow.keras.load_model(\"runs:/5d890004534c44f1880a0da3011c80d0/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.columns=['loss','val_loss']\n",
    "    hist_df.index = np.arange(1, len(hist_df)+1)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(hist_df.val_loss, lw=3, label='Validation Loss')\n",
    "    plt.plot(hist_df.loss, lw=3, label='Training Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.legend(loc=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- steps:** Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of None. If x is a tf.data dataset or a dataset iterator, and steps is None, predict will run until the input dataset is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:46:04.003630Z",
     "start_time": "2019-06-03T14:45:56.326242Z"
    }
   },
   "outputs": [],
   "source": [
    "train_angles = model.predict(ds_test, steps=len(test_metas)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:58:55.346167Z",
     "start_time": "2019-06-03T14:58:55.173698Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_angles, columns = ['angles'])\n",
    "df.angles.hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
