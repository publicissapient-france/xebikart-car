{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model to detect images with an obstacle on track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author : Johan Jublanc\n",
    "    \n",
    "Date : 20/09/2019\n",
    "\n",
    "Description : \n",
    "- Two type of data are collected : the first ones without any obstacle on the track, the other one with an obstacle\n",
    "- A pretrained model is downloaded and several layer are unfrozen so than the top convolutional layers can be retrained\n",
    "- The model make a prediction that can be used on a portion of the image (image cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "print(\"TensorFlow version is \", tf.__version__)\n",
    "\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xebikart.images import transformer as T\n",
    "\n",
    "import xebikart.dataset as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "decay = 0.00005\n",
    "\n",
    "model_name = \"detection_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "# dataset parameters\n",
    "tubes_root_folder = \"file:/workspace/xebikart-ml-tubes\"\n",
    "tubes_folders = [\n",
    "    \"tub.v4.02\",\n",
    "    \"tub.v6.01\"\n",
    "]\n",
    "test_size=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders, tubes_extension=\".tar.gz\")\n",
    "tubes_df = raw_tubes_df.rename(columns={\"cam/image_array\": \"images_path\", \"user/angle\": \"angles\", \"user/throttle\": \"throttles\"})\n",
    "tubes_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = tubes_df[\"images_path\"].tolist()\n",
    "labels = tubes_df[\"num_tube\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The paths are split into a train group and a test group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path, test_images_path, train_labels, test_labels = train_test_split(images_path, labels, test_size=test_size)\n",
    "print('Train set :', len(train_images_path), 'images')\n",
    "print('Test set :', len(test_images_path), 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the API data setto unzip and preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model take (160,160) normalized images. The following function process the data to fit the input of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_normalize(image_path):\n",
    "    tf_image = T.read_image(image_path)\n",
    "    tf_image = T.normalize(tf_image)\n",
    "    tf_image = tf.image.resize(tf_image,(160,160), method = 2)\n",
    "    return tf_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the API dataset is used to process and shuffle the data and make batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def input_fn(filepath, label, BATCH_SIZE = 32, SHUFFLE_SIZE = 200, NUM_EPOCHS = 50):\n",
    "    ds_x = tf.data.Dataset.from_tensor_slices(filepath)\n",
    "    ds_x = ds_x.map(resize_normalize)\n",
    "    ds_y = tf.data.Dataset.from_tensor_slices(label)\n",
    "    ds_x_y = tf.data.Dataset.zip((ds_x, ds_y)).shuffle(SHUFFLE_SIZE).repeat(NUM_EPOCHS).batch(BATCH_SIZE).prefetch(1)\n",
    "    \n",
    "    return ds_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = input_fn(train_images_path, train_labels, BATCH_SIZE = batch_size, SHUFFLE_SIZE = 100, NUM_EPOCHS = n_epochs)\n",
    "ds_test = input_fn(test_images_path, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = tubes_df[\"images_path\"]\n",
    "labels = tubes_df[\"num_tube\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = tubes_df.sample()[\"images_path\"].values[0]\n",
    "\n",
    "\n",
    "tf_image_original = T.read_image(random_image_path)\n",
    "tf_image_normalized = T.normalize(tf_image_original)\n",
    "tf_image_resized = tf.image.resize(tf_image_normalized,(160,160), method = 2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,15), constrained_layout=True)\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].imshow(tf_image_original)\n",
    "axs[1].set_title(\"normalized\")\n",
    "axs[1].imshow(tf_image_normalized)\n",
    "axs[2].set_title(\"resized\")\n",
    "axs[2].imshow(tf_image_resized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve a pretrained model to classify our images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_url = \"https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_1.0_224_quant_and_labels.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "r = requests.get(zip_file_url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 160\n",
    "IMG_SHAPE = (image_size, image_size, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose the number of layer to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_layer_train = 5\n",
    "nb_layer_freez = len(base_model.layers) - nb_layer_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:nb_layer_freez]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a look at the base model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add an output dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  keras.layers.GlobalAveragePooling2D(),\n",
    "  keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose the parameters and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr = learning_rate, \n",
    "                                                 decay = decay),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[Precision(), Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"convolutional_neural_network\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"images\": str(tubes_folders),\n",
    "        \"nb_images\": len(train_images_path),\n",
    "        \"epochs\": n_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"decay\": decay\n",
    "    })\n",
    "    mlflow.tensorflow.autolog()\n",
    "    history = model.fit(x = ds_train,\n",
    "                    steps_per_epoch = len(train_labels)//batch_size,\n",
    "                    epochs = n_epochs,\n",
    "                    verbose = 1,\n",
    "                    validation_data = ds_test,\n",
    "                    validation_steps = len(test_labels)//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vizualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_image_resized(im_path):\n",
    "    tf_image_original = T.read_image(im_path)\n",
    "    tf_image_normalized = T.normalize(tf_image_original)\n",
    "    tf_image_resized = tf.image.resize(tf_image_normalized,(160,160), method = 2)\n",
    "    tf_img = tf.reshape(tf_image_resized,(1,160,160,3))\n",
    "    \n",
    "    return tf_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path_0 = tubes_df[tubes_df.num_tube==0].sample()[\"images_path\"].values[0]\n",
    "random_image_path_1 = tubes_df[tubes_df.num_tube==1].sample()[\"images_path\"].values[0]\n",
    "\n",
    "img_0 = get_tf_image_resized(random_image_path_0)\n",
    "img_1 = get_tf_image_resized(random_image_path_1)\n",
    "    \n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15,15), constrained_layout=True)\n",
    "axs[0].set_title(\"Clear (0) : Predict ({})\".format(model.predict(img_0)))\n",
    "axs[0].imshow(T.read_image(random_image_path_0))\n",
    "axs[1].set_title(\"Obstacle (1) : Predict ({})\".format(model.predict(img_1)))\n",
    "axs[1].imshow(T.read_image(random_image_path_1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to detect an obstacle in a box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_image_resized_cropped(im_path,box):\n",
    "    tf_image_original = T.read_image(im_path)\n",
    "    tf_image_cropped = tf_image_original[box[0]:box[2], box[1]:box[3]]\n",
    "    tf_image_normalized = T.normalize(tf_image_cropped)\n",
    "    tf_image_resized = tf.image.resize(tf_image_normalized,(160,160), method = 2)\n",
    "    tf_img = tf.reshape(tf_image_resized,(1,160,160,3))\n",
    "    \n",
    "    return tf_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show an image and a blue on the same picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 60\n",
    "left = 4\n",
    "win_heigh = 58\n",
    "win_width = 150\n",
    "box = (top, left, top + win_heigh, left + win_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path_0 = tubes_df[tubes_df.num_tube==0].sample()[\"images_path\"].values[0]\n",
    "random_image_path_1 = tubes_df[tubes_df.num_tube==1].sample()[\"images_path\"].values[0]\n",
    "\n",
    "img_crop0 = get_tf_image_resized_cropped(random_image_path_0,box)\n",
    "img_crop1 = get_tf_image_resized_cropped(random_image_path_1,box)\n",
    "    \n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15,15), constrained_layout=True)\n",
    "axs[0].set_title(\"Clear (0) : Predict ({})\".format(model.predict(img_crop0)))\n",
    "axs[0].imshow(T.read_image(random_image_path_0))\n",
    "axs[0].plot([box[1],box[1]],[box[0],box[2]], color=\"C0\",linewidth=4)\n",
    "axs[0].plot([box[3],box[3]],[box[0],box[2]], color=\"C0\",linewidth=4)\n",
    "axs[0].plot([box[1],box[3]],[box[0],box[0]], color=\"C0\",linewidth=4)\n",
    "axs[0].plot([box[1],box[3]],[box[2],box[2]], color=\"C0\",linewidth=4)\n",
    "\n",
    "axs[1].set_title(\"Obstacle (1) : Predict ({})\".format(model.predict(img_crop1)))\n",
    "axs[1].imshow(T.read_image(random_image_path_1))\n",
    "axs[1].plot([box[1],box[1]],[box[0],box[2]], color=\"C0\",linewidth=4)\n",
    "axs[1].plot([box[3],box[3]],[box[0],box[2]], color=\"C0\",linewidth=4)\n",
    "axs[1].plot([box[1],box[3]],[box[0],box[0]], color=\"C0\",linewidth=4)\n",
    "axs[1].plot([box[1],box[3]],[box[2],box[2]], color=\"C0\",linewidth=4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
