{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.183798Z",
     "start_time": "2019-06-03T14:37:35.574034Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import pathlib\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import IPython.display as display\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from xebikart.images import transformer as T\n",
    "import xebikart.dataset as dataset\n",
    "# remove warning\n",
    "import xebikart.vae\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.189742Z",
     "start_time": "2019-06-03T14:37:37.185665Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager Execution allows to evaluate operations immediately without building graphs\n",
    "note : Only needed when not using TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:53:28.539899Z",
     "start_time": "2019-05-30T15:53:28.537757Z"
    }
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tubes from : https://github.com/xebia-france/xebikart-ml-tubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "# dataset parameters\n",
    "tubes_root_folder = \"file:/workspace/xebikart-ml-tubes\"\n",
    "tubes_folders = [\n",
    "    \"tub.v4.02\",\n",
    "    \"tub.v4.03\"\n",
    "]\n",
    "\n",
    "# vae\n",
    "vae_mlflow_run_id = \"e653a6fafe5b4dd1b446d6e763ecaf6b\"\n",
    "\n",
    "test_size=0.2\n",
    "\n",
    "# training parameters\n",
    "batch_size = 32\n",
    "shuffle_size = 200\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tubes from : https://github.com/xebia-france/xebikart-ml-tubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders, tubes_extension=\".tar.gz\")\n",
    "tubes_df = raw_tubes_df.rename(columns={\"cam/image_array\": \"images_path\", \"user/angle\": \"angles\", \"user/throttle\": \"throttles\"})\n",
    "tubes_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:13.603660Z",
     "start_time": "2019-05-30T15:54:13.601387Z"
    }
   },
   "source": [
    "#### **- Display some examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.474183Z",
     "start_time": "2019-06-03T14:37:37.466159Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15,15), constrained_layout=True)\n",
    "fig.suptitle(\"Angle / Throttle\", fontsize=20)\n",
    "\n",
    "for n, sample in tubes_df.sample(3).reset_index().iterrows():\n",
    "    random_image_path = sample[\"images_path\"]\n",
    "    angle = sample[\"angles\"]\n",
    "    throttle = sample[\"throttles\"]\n",
    "    image = mpimg.imread(random_image_path) \n",
    "    axs[n].set_title(f\"{angle} / {throttle}\")\n",
    "    axs[n].imshow(image)\n",
    "    axs[n].get_xaxis().set_visible(False)\n",
    "    axs[n].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Display some sample distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(15,5))\n",
    "axs[0].hist(tubes_df.angles)\n",
    "axs[0].set_title('distribution angles')\n",
    "axs[1].hist(tubes_df.throttles)\n",
    "axs[1].set_title('distribution throttles')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-30T15:54:48.159163Z",
     "start_time": "2019-05-30T15:54:48.156791Z"
    }
   },
   "source": [
    "# Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Images will be :**\n",
    "- Loaded\n",
    "    - Read images\n",
    "    - Decode jpeg images into uint8 tensor\n",
    "- Cropped\n",
    "    - Crop images on the lower part\n",
    "- Augmented\n",
    "    - Brightness : Adjust the brightness of images by a random factor.\n",
    "    - Saturation : Adjust the saturation of images by a random factor (must be RGB images)\n",
    "    - Contrast : Adjust the contrast of images by a random factor.\n",
    "    - Jpeg quality : Randomly changes jpeg encoding quality for inducing jpeg noise\n",
    "- Normalized\n",
    "    - Image are converted into Float32 between 0 and 1\n",
    "- Edged\n",
    "    - Convert tensor uint8 type into float32 type\n",
    "    - Convert rgb images to grayscale\n",
    "    - Reshape into [1, 80, 160, 1] tensor\n",
    "    - Apply sobel filter (see https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "    - Reshape into [80, 160, 2] tensor\n",
    "    - Select image gradient up to 0.3\n",
    "    - Binarize images by setting elements to 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **- Display some examples before and after preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vae_fn(vae):\n",
    "    vae_encoder = vae.get_layer('encoder')\n",
    "    def _transform(tf_image):\n",
    "        return tf.squeeze(vae_encoder.predict(tf.expand_dims(tf_image, 0), steps=1)[2])\n",
    "    return _transform\n",
    "\n",
    "crop_fn = T.generate_crop_fn(left_margin=0, width=160, height_margin=40, height=80)\n",
    "mlflow_vae = mlflow.keras.load_model(f\"runs:/{vae_mlflow_run_id}/model\", compile=False)\n",
    "mlflow_vae_fn = T.generate_vae_fn(mlflow_vae)\n",
    "\n",
    "def load_augmentation_preprocess(image_path):\n",
    "    tf_image = T.read_image(image_path)\n",
    "    tf_image = T.normalize(tf_image)\n",
    "    tf_image = crop_fn(tf_image)\n",
    "    tf_image = T.data_augmentation(tf_image)\n",
    "    tf_image = T.edges(tf_image)\n",
    "    tf_image = tf.py_function(mlflow_vae_fn, [tf_image], tf.float32)\n",
    "    # https://github.com/tensorflow/tensorflow/issues/28257\n",
    "    # https://stackoverflow.com/questions/42590431/output-from-tensorflow-py-func-has-unknown-rank-shape\n",
    "    # TODO: Get latent dimension from VAE\n",
    "    tf_image.set_shape((32,))\n",
    "    #tf_image = tf.reshape(tf_image, [-1])\n",
    "    return {'pixels': tf_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = tubes_df.sample()[\"images_path\"].values[0]\n",
    "\n",
    "tf_image_original   = T.read_image(random_image_path)\n",
    "tf_image_cropped    = crop_fn(tf_image_original)\n",
    "tf_image_augmented  = T.data_augmentation(tf_image_cropped)\n",
    "tf_image_normalized = T.normalize(tf_image_augmented)\n",
    "tf_image_edged      = T.edges(tf_image_normalized)\n",
    "tf_image_embedded   = mlflow_vae_fn(tf_image_edged)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(15,15), constrained_layout=True)\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].imshow(tf_image_original)\n",
    "axs[1].set_title(\"Cropping\")\n",
    "axs[1].imshow(tf_image_cropped)\n",
    "axs[2].set_title(\"Augmented\")\n",
    "axs[2].imshow(tf_image_augmented)\n",
    "axs[3].set_title(\"Preprocessed channel 1\")\n",
    "axs[3].imshow(tf_image_edged[:,:,0],cmap='gray')\n",
    "axs[4].set_title(\"Preprocessed channel 2\")\n",
    "axs[4].imshow(tf_image_edged[:,:,1],cmap='gray')\n",
    "plt.show()\n",
    "print(tf_image_embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a dataset of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Split data into test/train datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : We only use angle as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = tubes_df[\"images_path\"].tolist()\n",
    "metas_angle = tubes_df[\"angles\"].tolist()\n",
    "metas_throttle = tubes_df[\"throttles\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.201319Z",
     "start_time": "2019-06-03T14:37:37.196764Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images_path, test_images_path, train_metas, test_metas = train_test_split(images_path, metas_angle, test_size=test_size)\n",
    "print('Train set :', len(train_images_path), 'images')\n",
    "print('Test set :', len(test_images_path), 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **- Create tensor for train and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(filepath, label, batch_size=32, shuffle_size=200, n_epochs=50):\n",
    "    def _input_fn():\n",
    "        ds_x = tf.data.Dataset.from_tensor_slices(filepath)\n",
    "        ds_x = ds_x.map(load_augmentation_preprocess)\n",
    "        ds_y = tf.data.Dataset.from_tensor_slices(label)\n",
    "        ds_x_y = tf.data.Dataset.zip((ds_x, ds_y)).shuffle(shuffle_size).repeat(n_epochs).batch(batch_size).prefetch(1)\n",
    "        return ds_x_y\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = make_input_fn(train_images_path, train_metas)\n",
    "ds_test = make_input_fn(test_images_path, test_metas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- n_batches_per_layer:** the number of batches to collect statistics per layer. The total number of batches is total number of data divided by batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_col = tf.feature_column.numeric_column('pixels', shape=[32,])\n",
    "\n",
    "estimator = tf.estimator.BoostedTreesRegressor(\n",
    "    feature_columns=[image_col],\n",
    "    n_batches_per_layer=len(train_metas)//batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:38.649197Z",
     "start_time": "2019-06-03T14:37:38.436830Z"
    }
   },
   "outputs": [],
   "source": [
    "results = estimator.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.columns=['loss','val_loss']\n",
    "    hist_df.index = np.arange(1, len(hist_df)+1)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(hist_df.val_loss, lw=3, label='Validation Loss')\n",
    "    plt.plot(hist_df.loss, lw=3, label='Training Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(0,0.2)\n",
    "    plt.grid()\n",
    "    plt.legend(loc=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- steps:** Total number of steps (batches of samples) before declaring the prediction round finished. Ignored with the default value of None. If x is a tf.data dataset or a dataset iterator, and steps is None, predict will run until the input dataset is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:46:04.003630Z",
     "start_time": "2019-06-03T14:45:56.326242Z"
    }
   },
   "outputs": [],
   "source": [
    "train_angles = model.predict(ds_test, steps=len(test_metas)//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:58:55.346167Z",
     "start_time": "2019-06-03T14:58:55.173698Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_angles, columns = ['angles'])\n",
    "df.angles.hist(bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:56:58.668531Z",
     "start_time": "2019-06-03T14:56:58.374150Z"
    }
   },
   "outputs": [],
   "source": [
    "df.angles.plot.kde()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
