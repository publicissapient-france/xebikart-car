{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model to detect images with an obstacle on track and make a lite version of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author : Johan Jublanc\n",
    "    \n",
    "Date : 22/09/2019\n",
    "\n",
    "Description : \n",
    "\n",
    "Use the Python interpreter to load a .tflite file and run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO :_\n",
    "* Generalize this procedure to each model in the car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from xebikart.images import transformer as T\n",
    "\n",
    "import xebikart.dataset as dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tensorflow.compat.v1 import lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"detection_model\"\n",
    "resize_shape = (160,160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and convert the keras model (.h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model keras (.h5) is loaded and convert to a lite model (.tflite) which is lighter :\n",
    "* a smaller file thank to the serialization library FlatBuffer\n",
    "* a model smaller by reducing the precision of the numbers in the model\n",
    "\n",
    "See : \n",
    "* https://www.tensorflow.org/lite/performance/post_training_quantization\n",
    "* https://www.tensorflow.org/lite/convert/index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a converter using the keras model as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    converter = lite.TFLiteConverter.from_keras_model_file(model_name + \".h5\")\n",
    "except:\n",
    "    print(\"No model named {}.h5 in the current folder\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we parametrize an optimizer to quantize the model so that it is smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then convert the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally save the lite version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"{}.tflite\".format(model_name), \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the inference process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With tflite models, inferences are made thanks to an __interpreter__ that is fast and lean. We will define some functions to handle the whole prediction process with the Python API : \n",
    "* first, prepare the image -> read/normalize/resize/reshape/convert\n",
    "* second, define an interpreter and input and ouput details\n",
    "* finally, define a predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_path, resize_shape=(160,160)):\n",
    "    \n",
    "    tf_image = T.read_image(image_path)\n",
    "    tf_image = T.normalize(tf_image)\n",
    "    tf_image = tf.image.resize(tf_image,resize_shape, method = 2)\n",
    "    tf_image = tf.reshape(tf_image,(1,resize_shape[0],resize_shape[1],3))\n",
    "    tf_image = np.array(tf_image)\n",
    "    \n",
    "    return tf_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpreter_and_details(model_path) :\n",
    "\n",
    "    # Load TFLite model and allocate tensors\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path = model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    input_shape = input_details[0]['shape']\n",
    "    \n",
    "    return interpreter, input_details, output_details, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter, input_details, output_details, input_shape = interpreter_and_details(model_name + \".tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_builder(interpreter, input_details, output_details, input_shape):\n",
    "    def predictor(input_image):\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_image)\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # The function `get_tensor()` returns a copy of the tensor data.\n",
    "        # Use `tensor()` in order to get a pointer to the tensor.\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        return output_data[0][0]\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = predictor_builder(interpreter, input_details, output_details, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the inference process on a random image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset parameters\n",
    "tubes_root_folder = \"file:/workspace/xebikart-ml-tubes\"\n",
    "tubes_folders = [\n",
    "    \"tub.v4.02\",\n",
    "    \"tub.v6.01\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders, tubes_extension=\".tar.gz\")\n",
    "tubes_df = raw_tubes_df.rename(columns={\"cam/image_array\": \"images_path\", \"user/angle\": \"angles\", \"user/throttle\": \"throttles\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select 4 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = []\n",
    "for i in range(4):\n",
    "    random_image_path.append(tubes_df.sample()[\"images_path\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(15,15), constrained_layout=True)\n",
    "\n",
    "for i in range(4):\n",
    "    # function pre-defined are used to compute the prediction\n",
    "    image = prepare_image(random_image_path[i])\n",
    "    prediction = predictor(image)\n",
    "    \n",
    "    # eaxh image in shown with the prediction\n",
    "    axs[i].set_title(\"Prediction = {}\".format(prediction))\n",
    "    axs[i].imshow(image.reshape(resize_shape[0],resize_shape[1],3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
