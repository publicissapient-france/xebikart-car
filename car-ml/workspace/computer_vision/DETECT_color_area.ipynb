{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection color area\n",
    "\n",
    "Author : Johan Jublanc\n",
    "    \n",
    "Date : 06/11/2019\n",
    "\n",
    "Description : \n",
    "- detect area with a particular color\n",
    "- set bounding box around the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.183798Z",
     "start_time": "2019-06-03T14:37:35.574034Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import pathlib\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import IPython.display as display\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.losses import MSE, MSLE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "from xebikart.images import transformer as T\n",
    "import xebikart.dataset as dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.189742Z",
     "start_time": "2019-06-03T14:37:37.185665Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager Execution allows to evaluate operations immediately without building graphs\n",
    "note : Only needed when not using TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_root_folder = \"file:/workspace/xebikart-ml-tubes\"\n",
    "test_size=0.2\n",
    "\n",
    "# orange obstacle\n",
    "tubes_folders = [\"tub.v9.orange\"]\n",
    "#tubes_folders = [\"tub_29_19-11-18\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T14:37:37.474183Z",
     "start_time": "2019-06-03T14:37:37.466159Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders, tubes_extension=\".tar.gz\")\n",
    "tubes_df = raw_tubes_df.rename(columns={\"cam/image_array\": \"images_path\", \"user/angle\": \"angles\", \"user/throttle\": \"throttles\"})\n",
    "tubes_df.count()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,5), constrained_layout=True)\n",
    "fig.suptitle(\"Angle / Throttle\", fontsize=20)\n",
    "\n",
    "for n, sample in tubes_df.sample(3).reset_index().iterrows():\n",
    "    random_image_path = sample[\"images_path\"]\n",
    "    angle = sample[\"angles\"]\n",
    "    throttle = sample[\"throttles\"]\n",
    "    image = mpimg.imread(random_image_path) \n",
    "    axs[n].set_title(f\"{angle} / {throttle}\")\n",
    "    axs[n].imshow(image)\n",
    "    axs[n].get_xaxis().set_visible(False)\n",
    "    axs[n].get_yaxis().set_visible(False)\n",
    "print(\"size : {} images\".format(len(raw_tubes_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick up a color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = tubes_df.sample(1)[\"images_path\"].values[0]\n",
    "picked_up_pix = (42, 60)\n",
    "image = mpimg.imread(random_image_path) \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_image(tf_image, gain = 1.5,  saturation = 1.5, constraste = 1.2):\n",
    "    image_gain = tf.image.adjust_gamma(tf_image, gamma=1, gain=gain)\n",
    "    image_saturation = tf.image.adjust_saturation(image_gain, saturation)\n",
    "    image_contrast = tf.image.adjust_contrast(image_saturation, constraste)\n",
    "    \n",
    "    return image_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain = 1.4\n",
    "saturation = 2\n",
    "constraste = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picked_up_pix_yx = (55, 100)\n",
    "\n",
    "image = mpimg.imread(random_image_path)\n",
    "image_gain = tf.image.adjust_gamma(image, gamma=1, gain=gain)\n",
    "image_saturation = tf.image.adjust_saturation(image_gain, saturation)\n",
    "image_contrast = tf.image.adjust_contrast(image_saturation, constraste)\n",
    "color_detected = image_contrast[picked_up_pix_yx[0],picked_up_pix_yx[1]]\n",
    "color = tf.concat([tf.expand_dims(tf.fill([120, 160], color_detected[0]),-1),\n",
    "                   tf.expand_dims(tf.fill([120, 160], color_detected[1]),-1),\n",
    "                   tf.expand_dims(tf.fill([120, 160], color_detected[2]),-1)],2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(40,40), constrained_layout=True)\n",
    "axs[0].imshow(image)\n",
    "axs[1].imshow(image_gain)\n",
    "axs[2].imshow(image_saturation)\n",
    "\n",
    "axs[3].plot((picked_up_pix_yx[1],picked_up_pix_yx[1]), (0,120), c=\"red\")\n",
    "axs[3].plot((0,160), (picked_up_pix_yx[0],picked_up_pix_yx[0]), c=\"red\")\n",
    "axs[3].imshow(image_contrast)\n",
    "axs[4].imshow(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_chan_r = tf.concat([tf.expand_dims(image[:,:,0],-1),\n",
    "                          tf.expand_dims(tf.fill([120, 160], tf.dtypes.cast(0,tf.uint8)),-1),\n",
    "                          tf.expand_dims(tf.fill([120, 160], tf.dtypes.cast(0,tf.uint8)),-1)],2)\n",
    "\n",
    "image_chan_g = tf.concat([tf.expand_dims(tf.fill([120, 160], tf.dtypes.cast(0,tf.uint8)),-1),\n",
    "                          tf.expand_dims(image[:,:,1],-1),\n",
    "                          tf.expand_dims(tf.fill([120, 160], tf.dtypes.cast(0,tf.uint8)),-1)],2)\n",
    "\n",
    "image_chan_b = tf.concat([tf.expand_dims(tf.fill([120, 160], tf.dtypes.cast(0,tf.uint8)),-1),\n",
    "                          tf.expand_dims(tf.fill([120, 160], tf.dtypes.cast(0,tf.uint8)),-1),\n",
    "                          tf.expand_dims(image[:,:,0],-1)],2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10,15), constrained_layout=True)\n",
    "axs[0].imshow(image_chan_r)\n",
    "axs[1].imshow(image_chan_g)\n",
    "axs[2].imshow(image_chan_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/ Build a mask corresponding to the area\n",
    "\n",
    "Here we detect pixels corresponding to the color chosen with a margin of error. To be more accurate, each pixel $pix_i$ is composed of 3 values between 0 and 255, one for each color channel (red, green, blue).\n",
    "\n",
    "The formula we use is as follow : \n",
    "$$mask_i = \\mathbb{1}_{pix_i(R) = color(R) +/- \\epsilon}\\times \\mathbb{1}_{pix_i(G) = color(G) +/- \\epsilon} \\times \\mathbb{1}_{pix_i(B) = color(B) +/- \\epsilon}$$\n",
    "\n",
    "Where : \n",
    "- $mask_i$ is the pixel i of the one-channel image output (one channel beacause we just need a black and white mask)\n",
    "- $pix_i(R/G/B)$ value of the channel red/green/blue for the pixel $i$\n",
    "- $color(R/G/B)$ value of the channel red/green/blue for the color detected.\n",
    "\n",
    "That function keep the pixels that correspond to color that we want to detect for each RGB channel with amargin of error $\\epsilon$. The other pixels are ignored. For the pixel kept we return 1 and for the other we return 0.\n",
    "\n",
    "NB : for practical reason the following function inverse ones and zeros (we want to put the colored detected in black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_color_area(tf_image_original, color_to_detect, epsilon):\n",
    "    tf_image_original = tf.dtypes.cast(tf_image_original, tf.float32)\n",
    "    color_to_detect = tf.dtypes.cast(color_to_detect, tf.float32)\n",
    "    tf_boolean_channels = []\n",
    "    \n",
    "    for i in range(len(color_to_detect)):\n",
    "        tf_ = tf.where(((tf_image_original[:,:,i] < (color_to_detect[i] + epsilon))&\n",
    "                        (tf_image_original[:,:,i] > (color_to_detect[i] - epsilon))), \n",
    "                 tf.ones_like(tf_image_original[:,:,i]),\n",
    "                 tf.zeros_like(tf_image_original[:,:,i]))\n",
    "                 \n",
    "        \n",
    "        tf_boolean_channels.append(tf.expand_dims(tf_, axis=0, name=None))\n",
    "        \n",
    "    tf_sum = tf.math.reduce_sum(tf.concat(tf_boolean_channels, 0),0)\n",
    "        \n",
    "    return tf.where(tf_sum >= 3, tf.zeros_like(tf_sum), tf.ones_like(tf_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1/ Plot somme examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_sample = tubes_df.sample(10)[\"images_path\"].values[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 80\n",
    "\n",
    "fig, axs = plt.subplots(3, 4, figsize=(15,5), constrained_layout=True)\n",
    "for i in range(4):\n",
    "    # function pre-defined are used to compute the prediction\n",
    "    tf_image = T.read_image(tubes_sample[i])\n",
    "    image_gain = tf.image.adjust_gamma(tf_image, gamma=1, gain=gain)\n",
    "    image_saturation = tf.image.adjust_saturation(image_gain, saturation)\n",
    "    image_contrast = tf.image.adjust_contrast(image_saturation, constraste)\n",
    "    \n",
    "    # eaxh image in shown with the prediction\n",
    "    axs[0][i].imshow(tf_image)\n",
    "    axs[1][i].imshow(image_contrast)\n",
    "    axs[2][i].imshow(detect_color_area(image_contrast, color_to_detect = color_detected , epsilon=epsilon), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2/ Set a bounding box around the area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we sum detected pixel along each axis and keep the position for which at least $n$ pixels have been detected, where $n$ is a parameter. The for each axis we return the min and max positions where at least $n$ pixels have been detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_shape_in_box(tf_binary_mask, nb_pixel_min):\n",
    "    min_axis = []\n",
    "    max_axis = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        threshold = tf_binary_mask.shape[i] - nb_pixel_min\n",
    "        tf_sum_axisi = tf.math.reduce_sum(tf_binary_mask, axis=i)\n",
    "        min_ = tf.math.reduce_min(tf.where(tf_sum_axisi <= int(threshold)))\n",
    "        max_ = tf.math.reduce_max(tf.where(tf_sum_axisi <= int(threshold)))\n",
    "        min_axis.append(min_/tf_binary_mask.shape[(1-i)])\n",
    "        max_axis.append(max_/tf_binary_mask.shape[(1-i)])\n",
    "    \n",
    "    box = [min_axis[1], min_axis[0], max_axis[1], max_axis[0]]\n",
    "    box = tf.expand_dims(tf.expand_dims(box,0),0)\n",
    "    \n",
    "    return tf.dtypes.cast(box,dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_image_and_box(image_path, color_detected, epsilon, nb_pixel_min, gain = 1, output_original = True):\n",
    "    tf_image_original   = T.read_image(image_path)\n",
    "    tf_image_adjusted = adjust_image(tf_image_original, gain = 1.5,  saturation = 1.5, constraste = 1.2)\n",
    "\n",
    "    # Create a detection mask\n",
    "    tf_color_area = detect_color_area(tf_image_adjusted, color_detected, epsilon)\n",
    "    \n",
    "    # Create the boudning box\n",
    "    box = bounding_shape_in_box(tf_color_area, nb_pixel_min)\n",
    "\n",
    "    # Normilaze the original image\n",
    "    if output_original :\n",
    "        tf_image_normalized = tf.image.convert_image_dtype(tf_image_original, dtype=tf.float32)\n",
    "    else :\n",
    "        tf_image_normalized = tf.image.convert_image_dtype(tf_image_adjusted, dtype=tf.float32)\n",
    "    \n",
    "    tf_image_normalized = tf.expand_dims(tf_image_normalized, 0)\n",
    "    \n",
    "    return tf.image.draw_bounding_boxes(tf_image_normalized, box)[0,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1/ Plot some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pixel_min = 5\n",
    "j = 50\n",
    "r = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubes_df[\"images_path\"].values[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(4, 3, figsize=(15,15), constrained_layout=True)\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "for i in range(r):\n",
    "    random_image_path = tubes_df[\"images_path\"].values[i+j]\n",
    "    img = return_image_and_box(random_image_path, color_detected, epsilon, nb_pixel_min, gain=gain, output_original = False)\n",
    "    #clear_output()\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    #time.sleep(0.2)\n",
    "    axs[i//3][i%3].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
