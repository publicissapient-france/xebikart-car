{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author : Nicolas Laille/ Johan Jublanc\n",
    "    \n",
    "Date : 05/10/2019\n",
    "\n",
    "Description : \n",
    "\n",
    "Use a VAE to encode preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T12:36:08.521103Z",
     "start_time": "2019-06-14T12:36:07.476250Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8Erlqf6VOfB-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import tempfile\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import xebikart.dataset as dataset\n",
    "from xebikart.vae import create_variational_auto_encoder, custom_vae_loss\n",
    "import xebikart.images.transformer as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset parameters\n",
    "tubes_root_folder = 'file:/workspace/xebikart-ml-tubes'\n",
    "tubes_folders_road = [\"tub.v7.01\", \"tub.v7.02\"]\n",
    "tubes_folders_exit = [\"tub.v5.01\", \"tub.v5.02\"]#, \"tub.v5.03\", \"tub.v5.04\"]\n",
    "tubes_folders_obstacles = [\"tub.v8.02\"]\n",
    "\n",
    "image_folders = tubes_folders_road + tubes_folders_exit + tubes_folders_obstacles\n",
    "\n",
    "test_size=0.2\n",
    "\n",
    "# parameters\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "n_epochs = 20\n",
    "shuffle_size = 1024\n",
    "\n",
    "# Vae parameters\n",
    "latent_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%time\n",
    "road_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders_road, tubes_extension=\".tar.gz\")\n",
    "road_tubes_df['label'] = 0\n",
    "\n",
    "exit_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders_exit, tubes_extension=\".tar.gz\")\n",
    "exit_tubes_df['label'] = 1\n",
    "\n",
    "obstacles_tubes_df = dataset.get_tubes_df(tubes_root_folder, tubes_folders_obstacles, tubes_extension=\".tar.gz\")\n",
    "obstacles_tubes_df['label'] = 2\n",
    "\n",
    "tubes_df = pd.concat([road_tubes_df, exit_tubes_df, obstacles_tubes_df])\n",
    "tubes_df = tubes_df.rename(columns={\"cam/image_array\": \"images_path\"})\n",
    "tubes_df = tubes_df.drop([\"user/angle\", \"user/throttle\", \"user/mode\", \"timestamp\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = tubes_df[\"images_path\"].tolist()\n",
    "label = tubes_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path, test_images_path, train_metas, test_metas = train_test_split(images_path, label, test_size=test_size)\n",
    "print('Train set :', len(train_images_path), 'images')\n",
    "print('Test set :', len(test_images_path), 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:43:56.711109Z",
     "start_time": "2019-06-14T13:43:56.314190Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dQp3H_CyOfMj"
   },
   "outputs": [],
   "source": [
    "def plot_images(images, title):\n",
    "    n = len(images)\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(images[i][:,:,1], cmap = \"gray\")\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(images[i][:,:,1], cmap = \"gray\")\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the images and build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an image pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7JDNye9OfCd"
   },
   "source": [
    "**Images will be :**\n",
    "- Loaded\n",
    "    - Read images\n",
    "    - Decode jpeg images into uint8 tensor\n",
    "- Cropped\n",
    "    - Crop images on the lower part\n",
    "- Augmented\n",
    "    - Brightness : Adjust the brightness of images by a random factor.\n",
    "    - Saturation : Adjust the saturation of images by a random factor (must be RGB images)\n",
    "    - Contrast : Adjust the contrast of images by a random factor.\n",
    "    - Jpeg quality : Randomly changes jpeg encoding quality for inducing jpeg noise\n",
    "- Normalized\n",
    "    - Image are converted into Float32 between 0 and 1\n",
    "- Edged\n",
    "    - Convert tensor uint8 type into float32 type\n",
    "    - Convert rgb images to grayscale\n",
    "    - Reshape into [1, 80, 160, 1] tensor\n",
    "    - Apply sobel filter (see https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "    - Reshape into [80, 160, 2] tensor\n",
    "    - Select image gradient up to 0.3\n",
    "    - Binarize images by setting elements to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_fn = T.generate_crop_fn(left_margin=0, width=160, height_margin=40, height=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "    tf_image = T.read_image(image_path)\n",
    "    tf_image = T.normalize(tf_image)\n",
    "    tf_image = crop_fn(tf_image)\n",
    "    #tf_image = T.data_augmentation(tf_image)\n",
    "    tf_image = T.edges(tf_image)\n",
    "    return tf_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(filepath, label, preprocess):\n",
    "    ds_x = tf.data.Dataset.from_tensor_slices(filepath)\n",
    "    ds_x = ds_x.map(preprocess)\n",
    "    ds_y = tf.data.Dataset.from_tensor_slices(label)\n",
    "    # ds_x_y = tf.data.Dataset.zip((ds_x, ds_y)).shuffle(SHUFFLE_SIZE).repeat(NUM_EPOCHS).batch(BATCH_SIZE).prefetch(1)\n",
    "    \n",
    "    return ds_x, ds_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_image, ds_train_labels = input_fn(train_images_path, train_metas, preprocess=preprocess)\n",
    "ds_test_images, ds_test_labels = input_fn(test_images_path, test_metas, preprocess=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_image_batch = ds_train_image.shuffle(shuffle_size).repeat(n_epochs).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkH8qsWqOfLP"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = create_variational_auto_encoder(\n",
    "    input_shape=tf.compat.v1.data.get_output_shapes(ds_train_image_batch)[1:],\n",
    "    latent_dim=latent_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:09:33.973696Z",
     "start_time": "2019-06-14T13:09:33.949297Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pJnQADYkOfLU",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "vae.compile(optimizer, loss=custom_vae_loss(vae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the vae before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = ds_train_image_batch.make_one_shot_iterator()\n",
    "\n",
    "preprocessed_images = tf.compat.v1.Session().run(train_iterator.get_next())[:4]\n",
    "plot_images(preprocessed_images, \"Preprocessed images\")\n",
    "decoded_images = vae.predict(preprocessed_images)\n",
    "plot_images(decoded_images, \"Decoded images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:43:54.028454Z",
     "start_time": "2019-06-14T13:09:33.979170Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pHSnR2vOOfMC",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "n_samples = len(train_images_path)\n",
    "\n",
    "mlflow.set_experiment(\"variational_auto_encoder_edge\")\n",
    "# Create temp directory\n",
    "run_tempdir = tempfile.mkdtemp()\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    mlflow.log_params({\n",
    "        \"images\": str(image_folders),\n",
    "        \"nb_images\": shuffle_size,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"input_shape\": \"test\",#tf.compat.v1.data.get_output_shapes(ds_train_image_batch)[1:],\n",
    "        \"latent_dim\": latent_dim\n",
    "    })\n",
    "    mlflow.tensorflow.autolog()\n",
    "    vae.fit(ds_train_image_batch, epochs=n_epochs, steps_per_epoch=int(n_samples / batch_size))\n",
    "    # save encoder and lite encoder\n",
    "    # as keras model\n",
    "    \n",
    "    # TODO: TFLiteConverter reset tf graph, it creates issues if you want to continue to use this notebook afterwards\n",
    "    # TODO: find a solution\n",
    "    # as lite\n",
    "    #encoder_save_path = os.path.join(run_tempdir, \"encoder\")\n",
    "    #encoder.save(encoder_save_path + \".h5\")\n",
    "    #converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(encoder_save_path + \".h5\")\n",
    "    #converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "    #encoder_tflite = converter.convert()\n",
    "    #open(encoder_save_path + \".tflite\", \"wb+\").write(encoder_tflite)\n",
    "    #mlflow.log_artifact(encoder_save_path + \".tflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CSMqTOROfMR"
   },
   "source": [
    "## Test the VAE after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vae mlflow\n",
    "vae_id = \"5e7e7673cbc24e9da2d33ca37df0dda5\"\n",
    "vae = mlflow.keras.load_model(\"runs:/{}/model\".format(vae_id), compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = ds_test_images.batch(4).make_one_shot_iterator()\n",
    "\n",
    "preprocessed_images = tf.compat.v1.Session().run(train_iterator.get_next())[:4]\n",
    "plot_images(preprocessed_images, \"Preprocessed images\")\n",
    "decoded_images = vae.predict(preprocessed_images)\n",
    "plot_images(decoded_images, \"Decoded images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Model(inputs=vae.get_layer(\"encoder\").input, \n",
    "                             outputs=vae.get_layer(\"encoder\").get_layer(\"z_mean\").output)\n",
    "\n",
    "mlflow.keras.log_model(encoder, \"encoder\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "size = 5000\n",
    "train_iterator = ds_test_images.batch(size).make_one_shot_iterator()\n",
    "X_images = tf.compat.v1.Session().run(train_iterator.get_next())[:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and decode the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_images_encoded = encoder.predict(X_images)\n",
    "label_iterator = ds_test_labels.batch(size).make_one_shot_iterator()\n",
    "Y_labels = tf.compat.v1.Session().run(label_iterator.get_next())[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images_decoded = vae.predict(X_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE : Reduce the dimension to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set a seed\n",
    "RS = 2805\n",
    "\n",
    "# fit and transform the encoded images to reduce the dimensio to 2D\n",
    "fashion_tsne = TSNE(random_state=RS).fit_transform(X_images_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a dataframe with labels and 2D coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = [x[0] for x in fashion_tsne]\n",
    "x_2 = [x[1] for x in fashion_tsne]\n",
    "X_tsne = pd.DataFrame(list(zip(x_1,x_2,Y_labels)), columns=[\"x_1\", \"x_2\", \"color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose an image to highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_axes(fig):\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        ax.text(0.5, 0.5, \"ax%d\" % (i+1), va=\"center\", ha=\"center\")\n",
    "        ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "def plot_viz(X_tsne,point, image_original,image_decoded):\n",
    "    X = X_tsne\n",
    "    colors = X[\"color\"]\n",
    "\n",
    "    num_classes = len(np.unique(colors))\n",
    "    palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    ax1 = plt.subplot2grid((4, 9), (0, 0), colspan=5, rowspan=4)\n",
    "    ax2 = plt.subplot2grid((4, 9), (0, 5), colspan=2, rowspan=2)\n",
    "    ax3 = plt.subplot2grid((4, 9), (0, 7), colspan=2, rowspan=2)\n",
    "    ax4 = plt.subplot2grid((4, 9), (2, 5), colspan=2, rowspan=2)\n",
    "    ax5 = plt.subplot2grid((4, 9), (2, 7), colspan=2, rowspan=2)\n",
    "\n",
    "    ax2.imshow(image_original[:,:,0], cmap = \"gray\")\n",
    "    ax3.imshow(image_decoded[:,:,0], cmap = \"gray\")\n",
    "    ax4.imshow(image_original[:,:,1], cmap = \"gray\")\n",
    "    ax5.imshow(image_decoded[:,:,1], cmap = \"gray\")\n",
    "\n",
    "    # create a scatter plot.\n",
    "    #f = plt.figure(figsize=(8, 8))\n",
    "    ax1.scatter(X[\"x_1\"], X[\"x_2\"], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('tight')\n",
    "    ax2.axis('off')\n",
    "    ax3.axis('tight')\n",
    "    ax3.axis('off')\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "    ax5.axis('tight')\n",
    "    ax5.axis('off')\n",
    "\n",
    "\n",
    "    # add the labels for each digit corresponding to the label\n",
    "    txts = []\n",
    "    txt = ax1.text(point[0], point[1], \"x\", fontsize=24)\n",
    "    txt.set_path_effects([\n",
    "        PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "        PathEffects.Normal()])\n",
    "    txts.append(txt)\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for the label 0 (out road)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.choice([x for x in range(len(Y_labels)) if Y_labels[x]==0])\n",
    "\n",
    "point = fashion_tsne[rand]\n",
    "image_original = X_images[rand]\n",
    "image_decoded = X_images_decoded[rand]\n",
    "\n",
    "plot_viz(X_tsne,point, image_original,image_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for the label 1 (on track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 1\n",
    "rand = np.random.choice([x for x in range(len(Y_labels)) if Y_labels[x]==label])\n",
    "\n",
    "point = fashion_tsne[rand]\n",
    "image_original = X_images[rand]\n",
    "image_decoded = X_images_decoded[rand]\n",
    "\n",
    "plot_viz(X_tsne,point, image_original,image_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot for the label 2 (obstacle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 2\n",
    "rand = np.random.choice([x for x in range(len(Y_labels)) if Y_labels[x]==label])\n",
    "\n",
    "point = fashion_tsne[rand]\n",
    "image_original = X_images[rand]\n",
    "image_decoded = X_images_decoded[rand]\n",
    "\n",
    "plot_viz(X_tsne,point, image_original,image_decoded)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ODv_PceIOfFt",
    "UVY7XKRIOfGS",
    "WfLeCfB6OfG7",
    "qU3VkRYJOfIn",
    "LsAvI6q7OfJ9",
    "TZt06Fq6OfKN",
    "DbZ1pezyOfKY",
    "dkH8qsWqOfLP",
    "Zwb3avOmOfL_",
    "3CSMqTOROfMR",
    "oPH-MXL7OfMg"
   ],
   "name": "Formation_DL_Autoencoder.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
