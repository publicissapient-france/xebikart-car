{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T12:36:08.521103Z",
     "start_time": "2019-06-14T12:36:07.476250Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8Erlqf6VOfB-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import xebikart.dataset as dataset\n",
    "from xebikart.vae import create_variational_auto_encoder, custom_vae_loss\n",
    "import xebikart.images.transformer as images_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "\n",
    "# Vae parameters\n",
    "latent_dim = 32\n",
    "\n",
    "# Images\n",
    "image_root_folder = \"file:/workspace/xebikart-ml-tubes\"\n",
    "image_folders = [\n",
    "    \"tub.v1.03\",\n",
    "    \"tub.v1.04\",\n",
    "    \"tub.v1.05\",\n",
    "    \"tub.v2.01\",\n",
    "    \"tub.v4.02\",\n",
    "    \"tub.v4.03\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:43:56.711109Z",
     "start_time": "2019-06-14T13:43:56.314190Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dQp3H_CyOfMj"
   },
   "outputs": [],
   "source": [
    "def plot_images(images, title):\n",
    "    n = len(images)\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(images[i][:,:,0])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(images[i][:,:,1])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7JDNye9OfCd"
   },
   "source": [
    "**Images will be :**\n",
    "- Loaded\n",
    "    - Read images\n",
    "    - Decode jpeg images into uint8 tensor\n",
    "- Cropped\n",
    "    - Crop images on the lower part\n",
    "- Augmented\n",
    "    - Brightness : Adjust the brightness of images by a random factor.\n",
    "    - Saturation : Adjust the saturation of images by a random factor (must be RGB images)\n",
    "    - Contrast : Adjust the contrast of images by a random factor.\n",
    "    - Jpeg quality : Randomly changes jpeg encoding quality for inducing jpeg noise\n",
    "- Normalized\n",
    "    - Image are converted into Float32 between 0 and 1\n",
    "- Edged\n",
    "    - Convert tensor uint8 type into float32 type\n",
    "    - Convert rgb images to grayscale\n",
    "    - Reshape into [1, 80, 160, 1] tensor\n",
    "    - Apply sobel filter (see https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "    - Reshape into [80, 160, 2] tensor\n",
    "    - Select image gradient up to 0.3\n",
    "    - Binarize images by setting elements to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tubes\n",
    "tubes_path = dataset.get_tubes(image_root_folder, image_folders, tubes_extension=\".tar.gz\")\n",
    "n_samples = len(tubes_path)\n",
    "\n",
    "print(\"Images : {}\".format(n_samples))\n",
    "\n",
    "images_path_dataset = tf.data.Dataset.from_tensor_slices(tubes_path)\n",
    "images_dataset = images_path_dataset\\\n",
    "    .map(images_transformer.read_image)\\\n",
    "    .map(images_transformer.normalize)\\\n",
    "    .map(images_transformer.generate_crop_fn(left_margin=0, width=160, height_margin=40, height=80))\\\n",
    "    .map(images_transformer.data_augmentation)\\\n",
    "    .map(images_transformer.edges)\n",
    "train_dataset = images_dataset.shuffle(1024).batch(batch_size).repeat(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "\n",
    "preprocessed_images = tf.Session().run(train_iterator.get_next())[:4]\n",
    "plot_images(preprocessed_images, \"Preprocessed images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkH8qsWqOfLP"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = create_variational_auto_encoder(\n",
    "    input_shape=tf.compat.v1.data.get_output_shapes(train_dataset)[1:],\n",
    "    latent_dim=latent_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:09:33.973696Z",
     "start_time": "2019-06-14T13:09:33.949297Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pJnQADYkOfLU",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "vae.compile(optimizer, loss=custom_vae_loss(vae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:43:54.028454Z",
     "start_time": "2019-06-14T13:09:33.979170Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pHSnR2vOOfMC",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"variational_auto_encoder\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"images\": str(image_folders),\n",
    "        \"nb_images\": n_samples,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"input_shape\": tf.compat.v1.data.get_output_shapes(train_dataset)[1:],\n",
    "        \"latent_dim\": latent_dim\n",
    "    })\n",
    "    mlflow.tensorflow.autolog()\n",
    "    vae.fit(train_dataset, epochs=n_epochs, steps_per_epoch=int(n_samples / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CSMqTOROfMR"
   },
   "source": [
    "## Test VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "\n",
    "preprocessed_images = tf.Session().run(train_iterator.get_next())[:4]\n",
    "plot_images(preprocessed_images, \"Preprocessed images\")\n",
    "decoded_images = vae.predict(preprocessed_images)\n",
    "plot_images(decoded_images, \"Decoded images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae = mlflow.keras.load_model(\"runs:/2aaa0fa6498748ef89f5a71d2b9d1a37/model\", compile=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ODv_PceIOfFt",
    "UVY7XKRIOfGS",
    "WfLeCfB6OfG7",
    "qU3VkRYJOfIn",
    "LsAvI6q7OfJ9",
    "TZt06Fq6OfKN",
    "DbZ1pezyOfKY",
    "dkH8qsWqOfLP",
    "Zwb3avOmOfL_",
    "3CSMqTOROfMR",
    "oPH-MXL7OfMg"
   ],
   "name": "Formation_DL_Autoencoder.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
