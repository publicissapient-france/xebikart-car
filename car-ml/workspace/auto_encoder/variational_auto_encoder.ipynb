{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T12:36:08.521103Z",
     "start_time": "2019-06-14T12:36:07.476250Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8Erlqf6VOfB-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "import tempfile\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "\n",
    "import xebikart.dataset as dataset\n",
    "from xebikart.vae import create_variational_auto_encoder, custom_vae_loss\n",
    "import xebikart.images.transformer as images_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "\n",
    "# Vae parameters\n",
    "latent_dim = 32\n",
    "\n",
    "# Images\n",
    "image_root_folder = \"file:/workspace/xebikart-ml-tubes\"\n",
    "image_folders = [\n",
    "  \"tub.v1.03\",\n",
    "  \"tub.v1.04\",\n",
    "  \"tub.v1.05\",\n",
    "  \"tub.v2.01\",\n",
    "  \"tub.v4.02\",\n",
    "  \"tub.v4.03\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:43:56.711109Z",
     "start_time": "2019-06-14T13:43:56.314190Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dQp3H_CyOfMj"
   },
   "outputs": [],
   "source": [
    "def plot_images(images, title):\n",
    "    n = len(images)\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i+1)\n",
    "        plt.imshow(images[i][:,:,0],cmap='jet')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(images[i][:,:,1],cmap='jet')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7JDNye9OfCd"
   },
   "source": [
    "**Images will be :**\n",
    "- Loaded\n",
    "    - Read images\n",
    "    - Decode jpeg images into uint8 tensor\n",
    "- Cropped\n",
    "    - Crop images on the lower part\n",
    "- Augmented\n",
    "    - Brightness : Adjust the brightness of images by a random factor.\n",
    "    - Saturation : Adjust the saturation of images by a random factor (must be RGB images)\n",
    "    - Contrast : Adjust the contrast of images by a random factor.\n",
    "    - Jpeg quality : Randomly changes jpeg encoding quality for inducing jpeg noise\n",
    "- Normalized\n",
    "    - Image are converted into Float32 between 0 and 1\n",
    "- Edged\n",
    "    - Convert tensor uint8 type into float32 type\n",
    "    - Convert rgb images to grayscale\n",
    "    - Reshape into [1, 80, 160, 1] tensor\n",
    "    - Apply sobel filter (see https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "    - Reshape into [80, 160, 2] tensor\n",
    "    - Select image gradient up to 0.3\n",
    "    - Binarize images by setting elements to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tubes\n",
    "tubes_path = dataset.get_tubes(image_root_folder, image_folders, tubes_extension=\".tar.gz\")\n",
    "n_samples = len(tubes_path)\n",
    "\n",
    "print(\"Images : {}\".format(n_samples))\n",
    "\n",
    "images_path_dataset = tf.data.Dataset.from_tensor_slices(tubes_path)\n",
    "images_dataset = images_path_dataset\\\n",
    "    .map(images_transformer.read_image)\\\n",
    "    .map(images_transformer.normalize)\\\n",
    "    .map(images_transformer.generate_crop_fn(left_margin=0, width=160, height_margin=40, height=80))\\\n",
    "    .map(images_transformer.data_augmentation)\\\n",
    "    .map(images_transformer.edges)\n",
    "train_dataset = images_dataset.shuffle(1024).batch(batch_size).repeat(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "\n",
    "preprocessed_images = tf.compat.v1.Session().run(train_iterator.get_next())[:4]\n",
    "plot_images(preprocessed_images, \"Preprocessed images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkH8qsWqOfLP"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = create_variational_auto_encoder(\n",
    "    input_shape=tf.compat.v1.data.get_output_shapes(train_dataset)[1:],\n",
    "    latent_dim=latent_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:09:33.973696Z",
     "start_time": "2019-06-14T13:09:33.949297Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pJnQADYkOfLU",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "vae.compile(optimizer, loss=custom_vae_loss(vae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T13:43:54.028454Z",
     "start_time": "2019-06-14T13:09:33.979170Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pHSnR2vOOfMC",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"variational_auto_encoder\")\n",
    "# Create temp directory\n",
    "run_tempdir = tempfile.mkdtemp()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"images\": str(image_folders),\n",
    "        \"nb_images\": n_samples,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"input_shape\": tf.compat.v1.data.get_output_shapes(train_dataset)[1:],\n",
    "        \"latent_dim\": latent_dim\n",
    "    })\n",
    "    mlflow.tensorflow.autolog()\n",
    "    vae.fit(train_dataset, epochs=n_epochs, steps_per_epoch=int(n_samples / batch_size))\n",
    "    # save encoder and lite encoder\n",
    "    # as keras model\n",
    "    encoder = tf.keras.Model(inputs=vae.get_layer(\"encoder\").input, \n",
    "                             outputs=vae.get_layer(\"encoder\").get_layer(\"z_mean\").output)\n",
    "    mlflow.keras.log_model(encoder, \"encoder\", include_optimizer=False)\n",
    "    # TODO: TFLiteConverter reset tf graph, it creates issues if you want to continue to use this notebook afterwards\n",
    "    # TODO: find a solution\n",
    "    # as lite\n",
    "    #encoder_save_path = os.path.join(run_tempdir, \"encoder\")\n",
    "    #encoder.save(encoder_save_path + \".h5\")\n",
    "    #converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(encoder_save_path + \".h5\")\n",
    "    #converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "    #encoder_tflite = converter.convert()\n",
    "    #open(encoder_save_path + \".tflite\", \"wb+\").write(encoder_tflite)\n",
    "    #mlflow.log_artifact(encoder_save_path + \".tflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CSMqTOROfMR"
   },
   "source": [
    "## Test VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "\n",
    "preprocessed_images = tf.compat.v1.Session().run(train_iterator.get_next())[:4]\n",
    "plot_images(preprocessed_images, \"Preprocessed images\")\n",
    "decoded_images = vae.predict(preprocessed_images)\n",
    "plot_images(decoded_images, \"Decoded images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vae mlflow\n",
    "#vae = mlflow.keras.load_model(\"runs:/1882ffed18594d8abba5239f106f7efe/model\", compile=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ODv_PceIOfFt",
    "UVY7XKRIOfGS",
    "WfLeCfB6OfG7",
    "qU3VkRYJOfIn",
    "LsAvI6q7OfJ9",
    "TZt06Fq6OfKN",
    "DbZ1pezyOfKY",
    "dkH8qsWqOfLP",
    "Zwb3avOmOfL_",
    "3CSMqTOROfMR",
    "oPH-MXL7OfMg"
   ],
   "name": "Formation_DL_Autoencoder.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
